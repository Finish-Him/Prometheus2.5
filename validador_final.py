#!/usr/bin/env python3
"""
Validador Final da Migra√ß√£o JSON - Projeto Prometheus
Verifica integridade, qualidade e estat√≠sticas dos dados migrados
"""

import json
import os
import hashlib
from pathlib import Path
from collections import defaultdict, Counter
import jsonschema
from datetime import datetime

def carregar_schema():
    """Carrega o schema core_v1 para valida√ß√£o"""
    try:
        with open('schemas/core_v1.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("‚ö†Ô∏è  Schema core_v1.json n√£o encontrado, pulando valida√ß√£o de schema")
        return None

def validar_arquivo_json(caminho_arquivo, schema=None):
    """Valida um arquivo JSON individual"""
    resultado = {
        'arquivo': str(caminho_arquivo),
        'valido': False,
        'tamanho_bytes': 0,
        'schema_valido': False,
        'tem_metadados': False,
        'data_type': None,
        'source': None,
        'confidence': None,
        'importance': None,
        'erros': []
    }
    
    try:
        # Verificar tamanho do arquivo
        resultado['tamanho_bytes'] = caminho_arquivo.stat().st_size
        
        # Carregar JSON
        with open(caminho_arquivo, 'r', encoding='utf-8') as f:
            dados = json.load(f)
        
        resultado['valido'] = True
        
        # Verificar campos obrigat√≥rios
        if 'schema_version' in dados:
            resultado['schema_valido'] = dados.get('schema_version') == 'core_v1'
        
        if 'metadata' in dados:
            resultado['tem_metadados'] = True
        
        resultado['data_type'] = dados.get('data_type')
        resultado['source'] = dados.get('source')
        resultado['confidence'] = dados.get('confidence')
        resultado['importance'] = dados.get('importance')
        
        # Validar contra schema se dispon√≠vel
        if schema:
            try:
                jsonschema.validate(dados, schema)
                resultado['schema_valido'] = True
            except jsonschema.ValidationError as e:
                resultado['erros'].append(f"Schema inv√°lido: {e.message}")
        
    except json.JSONDecodeError as e:
        resultado['erros'].append(f"JSON inv√°lido: {e}")
    except Exception as e:
        resultado['erros'].append(f"Erro geral: {e}")
    
    return resultado

def gerar_estatisticas(resultados):
    """Gera estat√≠sticas detalhadas da valida√ß√£o"""
    stats = {
        'total_arquivos': len(resultados),
        'arquivos_validos': 0,
        'arquivos_com_schema': 0,
        'arquivos_com_metadados': 0,
        'tamanho_total_mb': 0,
        'por_data_type': Counter(),
        'por_source': Counter(),
        'por_importance': Counter(),
        'confidence_media': 0,
        'arquivos_com_erros': 0,
        'erros_unicos': set()
    }
    
    confidences = []
    
    for resultado in resultados:
        if resultado['valido']:
            stats['arquivos_validos'] += 1
        
        if resultado['schema_valido']:
            stats['arquivos_com_schema'] += 1
        
        if resultado['tem_metadados']:
            stats['arquivos_com_metadados'] += 1
        
        stats['tamanho_total_mb'] += resultado['tamanho_bytes'] / (1024 * 1024)
        
        if resultado['data_type']:
            stats['por_data_type'][resultado['data_type']] += 1
        
        if resultado['source']:
            stats['por_source'][resultado['source']] += 1
        
        if resultado['importance']:
            stats['por_importance'][resultado['importance']] += 1
        
        if resultado['confidence']:
            confidences.append(resultado['confidence'])
        
        if resultado['erros']:
            stats['arquivos_com_erros'] += 1
            for erro in resultado['erros']:
                stats['erros_unicos'].add(erro)
    
    if confidences:
        stats['confidence_media'] = sum(confidences) / len(confidences)
    
    return stats

def main():
    """Fun√ß√£o principal de valida√ß√£o"""
    print("üîç Iniciando Valida√ß√£o Final da Migra√ß√£o JSON - Projeto Prometheus")
    print("=" * 70)
    
    # Carregar schema
    schema = carregar_schema()
    
    # Encontrar todos os arquivos JSON
    data_dir = Path('data')
    if not data_dir.exists():
        print("‚ùå Diret√≥rio 'data' n√£o encontrado!")
        return
    
    arquivos_json = list(data_dir.rglob('*.json'))
    print(f"üìÅ Encontrados {len(arquivos_json)} arquivos JSON para valida√ß√£o")
    
    # Validar cada arquivo
    resultados = []
    print("\nüîÑ Validando arquivos...")
    
    for i, arquivo in enumerate(arquivos_json, 1):
        print(f"  [{i:2d}/{len(arquivos_json)}] {arquivo.name}", end="")
        resultado = validar_arquivo_json(arquivo, schema)
        resultados.append(resultado)
        
        if resultado['valido']:
            print(" ‚úÖ")
        else:
            print(" ‚ùå")
    
    # Gerar estat√≠sticas
    print("\nüìä Gerando estat√≠sticas...")
    stats = gerar_estatisticas(resultados)
    
    # Exibir relat√≥rio
    print("\n" + "=" * 70)
    print("üìã RELAT√ìRIO DE VALIDA√á√ÉO FINAL")
    print("=" * 70)
    
    print(f"üìÅ Total de arquivos: {stats['total_arquivos']}")
    print(f"‚úÖ Arquivos v√°lidos: {stats['arquivos_validos']} ({stats['arquivos_validos']/stats['total_arquivos']*100:.1f}%)")
    print(f"üîß Com schema core_v1: {stats['arquivos_com_schema']} ({stats['arquivos_com_schema']/stats['total_arquivos']*100:.1f}%)")
    print(f"üìã Com metadados: {stats['arquivos_com_metadados']} ({stats['arquivos_com_metadados']/stats['total_arquivos']*100:.1f}%)")
    print(f"üíæ Tamanho total: {stats['tamanho_total_mb']:.2f} MB")
    print(f"üéØ Confian√ßa m√©dia: {stats['confidence_media']:.3f}")
    print(f"‚ùå Arquivos com erros: {stats['arquivos_com_erros']}")
    
    print("\nüìä DISTRIBUI√á√ÉO POR CATEGORIA:")
    print("-" * 40)
    for data_type, count in stats['por_data_type'].most_common():
        print(f"  {data_type}: {count} arquivos")
    
    print("\nüìä DISTRIBUI√á√ÉO POR FONTE:")
    print("-" * 40)
    for source, count in stats['por_source'].most_common():
        print(f"  {source}: {count} arquivos")
    
    print("\nüìä DISTRIBUI√á√ÉO POR IMPORT√ÇNCIA:")
    print("-" * 40)
    for importance, count in stats['por_importance'].most_common():
        print(f"  N√≠vel {importance}: {count} arquivos")
    
    if stats['erros_unicos']:
        print("\n‚ö†Ô∏è  ERROS ENCONTRADOS:")
        print("-" * 40)
        for erro in sorted(stats['erros_unicos']):
            print(f"  ‚Ä¢ {erro}")
    
    # Salvar relat√≥rio detalhado
    relatorio_detalhado = {
        'timestamp': datetime.now().isoformat(),
        'estatisticas': stats,
        'arquivos_detalhados': resultados
    }
    
    with open('relatorio_validacao_detalhado.json', 'w', encoding='utf-8') as f:
        json.dump(relatorio_detalhado, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nüíæ Relat√≥rio detalhado salvo em: relatorio_validacao_detalhado.json")
    
    # Status final
    if stats['arquivos_com_erros'] == 0:
        print("\nüéâ MIGRA√á√ÉO VALIDADA COM SUCESSO!")
        print("   Todos os arquivos est√£o √≠ntegros e prontos para uso.")
    else:
        print(f"\n‚ö†Ô∏è  MIGRA√á√ÉO CONCLU√çDA COM {stats['arquivos_com_erros']} ARQUIVOS COM PROBLEMAS")
        print("   Verifique os erros acima e corrija se necess√°rio.")
    
    print("\nüöÄ Projeto Prometheus pronto para a pr√≥xima fase!")

if __name__ == "__main__":
    main()

