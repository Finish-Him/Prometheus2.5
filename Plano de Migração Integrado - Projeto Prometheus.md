# Plano de Migra√ß√£o Integrado - Projeto Prometheus

**Data:** 08/07/2025  
**Vers√£o:** 2.0  
**Objetivo:** Migra√ß√£o completa para JSON padronizado (schema core_v1)  
**Prazo:** 4 semanas (MVP para The International)

## Resumo Executivo

A an√°lise completa revelou um ecossistema complexo com **26.902 arquivos** totalizando **1.527 MB**, distribu√≠dos entre reposit√≥rios externos e sistema anterior. A migra√ß√£o para JSON padronizado √© cr√≠tica para viabilizar o projeto Prometheus e deve ser executada em fases priorizadas por import√¢ncia e confiabilidade.

### Invent√°rio Completo
- **Reposit√≥rios Externos:** 11 reposit√≥rios (26.601 arquivos, 1.299 MB)
- **Sistema Anterior:** 4 componentes (301 arquivos, 228 MB)
- **Total de JSONs Existentes:** 1.073 arquivos
- **Total de C√≥digo Python:** 210 arquivos
- **Modelos ML Treinados:** 19 arquivos

## Matriz de Prioriza√ß√£o

### üî¥ PRIORIDADE CR√çTICA (Semana 1)

#### 1. dotaconstants-master
- **Import√¢ncia:** 5/5 | **Confian√ßa:** 0.95/1.0
- **Conte√∫do:** 36 JSONs com constantes fundamentais do Dota 2
- **Migra√ß√£o:** Direto para `data/constants/` com valida√ß√£o schema core_v1
- **Impacto:** Base essencial para todos os modelos

#### 2. Sistema Anterior - Dados JSON
- **Import√¢ncia:** 5/5 | **Confian√ßa:** 0.8/1.0
- **Conte√∫do:** 66 JSONs com dados hist√≥ricos e an√°lises
- **Categorias Cr√≠ticas:**
  - 19 arquivos de partidas (matches)
  - 3 arquivos de her√≥is (heroes)
  - 3 arquivos de times (teams)
  - 2 arquivos de ligas (leagues)
- **Migra√ß√£o:** Consolida√ß√£o e normaliza√ß√£o para schema core_v1

### üü° PRIORIDADE ALTA (Semana 2)

#### 3. Sistema Anterior - Modelos ML
- **Import√¢ncia:** 4/5 | **Confian√ßa:** 0.85/1.0
- **Conte√∫do:** 19 modelos treinados (.pkl)
- **Categorias:**
  - 7 modelos de regress√£o
  - 4 modelos ensemble
  - 4 modelos otimizados
  - 4 preprocessadores
- **Migra√ß√£o:** Valida√ß√£o, documenta√ß√£o e migra√ß√£o para `models/`

#### 4. opendota_data
- **Import√¢ncia:** 4/5 | **Confian√ßa:** 0.75/1.0
- **Conte√∫do:** 80 arquivos de partidas hist√≥ricas
- **Migra√ß√£o:** Normaliza√ß√£o e enriquecimento com constantes

### üü¢ PRIORIDADE MODERADA (Semana 3)

#### 5. Sistema Anterior - C√≥digo Python
- **Import√¢ncia:** 4/5 | **Confian√ßa:** 0.7/1.0
- **Conte√∫do:** 166 scripts Python
- **Categorias:**
  - An√°lise de dados (40+ scripts)
  - Processamento de dados (30+ scripts)
  - Visualiza√ß√£o (20+ scripts)
  - Modelagem (15+ scripts)
- **Migra√ß√£o:** Consolida√ß√£o, refatora√ß√£o e padroniza√ß√£o

#### 6. Protobufs-master
- **Import√¢ncia:** 4/5 | **Confian√ßa:** 0.90/1.0
- **Conte√∫do:** 476 arquivos .proto
- **Migra√ß√£o:** Convers√£o para metadados JSON

### üîµ PRIORIDADE BAIXA (Semana 4)

#### 7. Projetos de An√°lise (Prometheus1.1, opendota_analysis_project)
- **Import√¢ncia:** 3/5 | **Confian√ßa:** 0.80/1.0
- **Migra√ß√£o:** Consolida√ß√£o e elimina√ß√£o de duplica√ß√µes

#### 8. Sistema Anterior - Documenta√ß√£o TXT
- **Import√¢ncia:** 3/5 | **Confian√ßa:** 0.7/1.0
- **Conte√∫do:** 54 arquivos de an√°lises documentadas
- **Migra√ß√£o:** Convers√£o para metadados estruturados

## Estrutura de Destino

```
prometheus/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ constants/           # dotaconstants-master
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ heroes.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ items.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ abilities.json
‚îÇ   ‚îú‚îÄ‚îÄ matches/            # Sistema anterior + opendota_data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ historical/
‚îÇ   ‚îú‚îÄ‚îÄ teams/              # Dados de times consolidados
‚îÇ   ‚îú‚îÄ‚îÄ leagues/            # Dados de ligas
‚îÇ   ‚îî‚îÄ‚îÄ analysis/           # Resultados de an√°lises
‚îú‚îÄ‚îÄ models/                 # Modelos ML do sistema anterior
‚îÇ   ‚îú‚îÄ‚îÄ production/
‚îÇ   ‚îú‚îÄ‚îÄ experimental/
‚îÇ   ‚îî‚îÄ‚îÄ metadata/
‚îú‚îÄ‚îÄ src/                    # C√≥digo Python consolidado
‚îÇ   ‚îú‚îÄ‚îÄ data_processing/
‚îÇ   ‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îú‚îÄ‚îÄ modeling/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ schemas/                # Schemas de valida√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ core_v1.json
‚îÇ   ‚îú‚îÄ‚îÄ match_v2.json
‚îÇ   ‚îî‚îÄ‚îÄ model_metadata.json
‚îú‚îÄ‚îÄ meta/                   # Metadados de cole√ß√µes
‚îî‚îÄ‚îÄ reports/                # Relat√≥rios de qualidade
```

## Schema Core V1 - Especifica√ß√£o

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "schema_version": {"const": "core_v1"},
    "data_type": {
      "enum": ["match", "hero", "item", "team", "league", "constant", "analysis", "model"]
    },
    "source": {
      "enum": ["opendota_api", "sistema_anterior", "dotaconstants", "manual"]
    },
    "timestamp": {"type": "string", "format": "date-time"},
    "confidence": {"type": "number", "minimum": 0, "maximum": 1},
    "importance": {"type": "integer", "minimum": 1, "maximum": 5},
    "validation_status": {"enum": ["passed", "failed", "pending"]},
    "metadata": {
      "type": "object",
      "properties": {
        "origin_file": {"type": "string"},
        "collection": {"type": "string"},
        "hash": {"type": "string"}
      }
    },
    "data": {"type": "object"}
  },
  "required": ["schema_version", "data_type", "source", "timestamp", "data"]
}
```


## Scripts de Migra√ß√£o

### 1. Script Principal de Migra√ß√£o

```python
#!/usr/bin/env python3
"""
Script Principal de Migra√ß√£o - Projeto Prometheus
Migra todos os dados para JSON padronizado schema core_v1
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import hashlib
import jsonschema

class MigradorPrometheus:
    def __init__(self):
        self.schema_core_v1 = self.carregar_schema()
        self.timestamp = datetime.now().isoformat()
        
    def migrar_dotaconstants(self, origem: Path, destino: Path):
        """Migra constantes do Dota 2"""
        for json_file in origem.rglob('*.json'):
            with open(json_file, 'r') as f:
                data = json.load(f)
            
            migrado = {
                "schema_version": "core_v1",
                "data_type": "constant",
                "source": "dotaconstants",
                "timestamp": self.timestamp,
                "confidence": 0.95,
                "importance": 5,
                "validation_status": "pending",
                "metadata": {
                    "origin_file": json_file.name,
                    "collection": "constants",
                    "hash": self.calcular_hash(data)
                },
                "data": data
            }
            
            # Validar contra schema
            try:
                jsonschema.validate(migrado, self.schema_core_v1)
                migrado["validation_status"] = "passed"
            except:
                migrado["validation_status"] = "failed"
            
            # Salvar
            output_file = destino / f"{json_file.stem}_{migrado['metadata']['hash'][:8]}.json"
            with open(output_file, 'w') as f:
                json.dump(migrado, f, indent=2, ensure_ascii=False)
    
    def migrar_sistema_anterior_json(self, origem: Path, destino: Path):
        """Migra JSONs do sistema anterior"""
        for json_file in origem.rglob('*.json'):
            if 'client_secret' in json_file.name:
                continue  # Pular arquivos de configura√ß√£o sens√≠veis
                
            with open(json_file, 'r') as f:
                data = json.load(f)
            
            # Determinar tipo baseado no nome do arquivo
            data_type = self.determinar_tipo_dados(json_file.name)
            
            migrado = {
                "schema_version": "core_v1",
                "data_type": data_type,
                "source": "sistema_anterior",
                "timestamp": self.timestamp,
                "confidence": 0.8,
                "importance": self.calcular_importancia(data_type),
                "validation_status": "pending",
                "metadata": {
                    "origin_file": json_file.name,
                    "collection": data_type,
                    "hash": self.calcular_hash(data)
                },
                "data": data
            }
            
            # Validar e salvar
            try:
                jsonschema.validate(migrado, self.schema_core_v1)
                migrado["validation_status"] = "passed"
            except:
                migrado["validation_status"] = "failed"
            
            output_dir = destino / data_type
            output_dir.mkdir(exist_ok=True)
            output_file = output_dir / f"{json_file.stem}_{migrado['metadata']['hash'][:8]}.json"
            
            with open(output_file, 'w') as f:
                json.dump(migrado, f, indent=2, ensure_ascii=False)
```

### 2. Script de Valida√ß√£o

```python
def validar_migracao():
    """Valida todos os JSONs migrados"""
    total_arquivos = 0
    arquivos_validos = 0
    erros = []
    
    for json_file in Path('data').rglob('*.json'):
        total_arquivos += 1
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
            
            jsonschema.validate(data, schema_core_v1)
            arquivos_validos += 1
        except Exception as e:
            erros.append(f"{json_file}: {str(e)}")
    
    print(f"Valida√ß√£o: {arquivos_validos}/{total_arquivos} arquivos v√°lidos")
    return len(erros) == 0
```

## Cronograma Detalhado

### Semana 1: Funda√ß√£o Cr√≠tica (08-14 Jul)

#### Dia 1-2: Setup e Constantes
- [ ] Criar estrutura de diret√≥rios
- [ ] Implementar schema core_v1
- [ ] Migrar dotaconstants-master (36 JSONs)
- [ ] Validar constantes migradas
- [ ] **Entrega:** Base de constantes validada

#### Dia 3-4: Sistema Anterior - JSONs Cr√≠ticos
- [ ] Migrar arquivos de partidas (19 JSONs)
- [ ] Migrar dados de her√≥is (3 JSONs)
- [ ] Migrar dados de times (3 JSONs)
- [ ] Normalizar e enriquecer dados
- [ ] **Entrega:** Dados hist√≥ricos estruturados

#### Dia 5-7: Valida√ß√£o e Testes
- [ ] Implementar testes automatizados
- [ ] Validar integridade dos dados
- [ ] Criar relat√≥rios de qualidade
- [ ] **Entrega:** Pipeline de valida√ß√£o funcional

### Semana 2: Modelos e Dados Hist√≥ricos (15-21 Jul)

#### Dia 8-10: Modelos ML
- [ ] Migrar modelos de regress√£o (7 arquivos)
- [ ] Migrar modelos ensemble (4 arquivos)
- [ ] Migrar modelos otimizados (4 arquivos)
- [ ] Documentar metadados dos modelos
- [ ] **Entrega:** Biblioteca de modelos validada

#### Dia 11-14: Dados OpenDota
- [ ] Migrar opendota_data (80 arquivos)
- [ ] Enriquecer com constantes
- [ ] Validar consist√™ncia temporal
- [ ] **Entrega:** Dataset hist√≥rico completo

### Semana 3: C√≥digo e Infraestrutura (22-28 Jul)

#### Dia 15-17: Consolida√ß√£o de C√≥digo
- [ ] Refatorar scripts de an√°lise (40+ arquivos)
- [ ] Consolidar processamento de dados (30+ arquivos)
- [ ] Padronizar visualiza√ß√µes (20+ arquivos)
- [ ] **Entrega:** Biblioteca de c√≥digo unificada

#### Dia 18-21: Protobufs e Metadados
- [ ] Converter Protobufs para metadados JSON
- [ ] Implementar CI/CD pipeline
- [ ] Configurar alertas Slack
- [ ] **Entrega:** Infraestrutura automatizada

### Semana 4: Finaliza√ß√£o e Testes (29 Jul - 04 Ago)

#### Dia 22-24: Projetos Legados
- [ ] Consolidar Prometheus1.1
- [ ] Eliminar duplica√ß√µes
- [ ] Migrar documenta√ß√£o TXT
- [ ] **Entrega:** Projeto consolidado

#### Dia 25-28: Testes Finais
- [ ] Testes de integra√ß√£o completos
- [ ] Benchmarks de performance
- [ ] Documenta√ß√£o final
- [ ] **Entrega:** Sistema pronto para produ√ß√£o

## M√©tricas de Sucesso

### Quantitativas
- **JSONs Migrados:** ‚â• 1.000 arquivos
- **Taxa de Valida√ß√£o:** 100% dos JSONs passam no schema core_v1
- **Redu√ß√£o de Duplica√ß√£o:** ‚â• 90% de arquivos duplicados eliminados
- **Cobertura de Testes:** ‚â• 80% do c√≥digo testado
- **Tempo de Ingest√£o:** < 60 min para 10.000 partidas

### Qualitativas
- **Padroniza√ß√£o:** 100% dos dados em formato JSON core_v1
- **Documenta√ß√£o:** Cobertura completa de APIs e processos
- **Observabilidade:** Logs estruturados e alertas funcionais
- **Confiabilidade:** Sistema robusto com tratamento de erros

## Riscos e Mitiga√ß√µes

### Riscos Cr√≠ticos

#### 1. Perda de Dados Durante Migra√ß√£o
- **Probabilidade:** M√©dia
- **Impacto:** Alto
- **Mitiga√ß√£o:** 
  - Backup completo antes da migra√ß√£o
  - Valida√ß√£o por checksums
  - Rollback autom√°tico em caso de falha

#### 2. Incompatibilidade de Schemas
- **Probabilidade:** Alta
- **Impacto:** M√©dio
- **Mitiga√ß√£o:**
  - Testes extensivos com dados de amostra
  - Schema versionado com backward compatibility
  - Valida√ß√£o incremental

#### 3. Performance Degradada
- **Probabilidade:** M√©dia
- **Impacto:** M√©dio
- **Mitiga√ß√£o:**
  - Benchmarks antes e depois
  - Otimiza√ß√£o de queries
  - Indexa√ß√£o adequada

### Riscos Operacionais

#### 4. Resist√™ncia da Equipe
- **Probabilidade:** Baixa
- **Impacto:** M√©dio
- **Mitiga√ß√£o:**
  - Treinamento adequado
  - Documenta√ß√£o clara
  - Canal de suporte dedicado

#### 5. Prazo Apertado (The International)
- **Probabilidade:** Alta
- **Impacto:** Alto
- **Mitiga√ß√£o:**
  - Prioriza√ß√£o rigorosa
  - MVP funcional em 3 semanas
  - Paraleliza√ß√£o de tarefas

## Entreg√°veis Finais

### 1. Dados Migrados
- **1.073+ JSONs** validados contra schema core_v1
- **Estrutura padronizada** em `data/`
- **Metadados completos** para rastreabilidade

### 2. C√≥digo Consolidado
- **210 scripts Python** refatorados e organizados
- **Biblioteca unificada** em `src/`
- **Testes automatizados** com pytest

### 3. Modelos Documentados
- **19 modelos ML** com metadados completos
- **Pipeline de retreino** automatizado
- **Versionamento** de modelos

### 4. Infraestrutura
- **CI/CD pipeline** com GitHub Actions
- **Alertas Slack** para falhas
- **Monitoramento** de qualidade de dados

### 5. Documenta√ß√£o
- **README abrangente** com guias de uso
- **API documentation** completa
- **Runbooks** operacionais

## Pr√≥ximos Passos Imediatos

1. **Aprova√ß√£o do Plano** - Valida√ß√£o com stakeholders
2. **Setup do Ambiente** - Prepara√ß√£o da infraestrutura
3. **In√≠cio da Migra√ß√£o** - Execu√ß√£o da Semana 1
4. **Monitoramento Cont√≠nuo** - Acompanhamento di√°rio do progresso

**O sucesso do projeto Prometheus depende da execu√ß√£o disciplinada deste plano de migra√ß√£o, com foco na qualidade, padroniza√ß√£o e observabilidade dos dados.**

